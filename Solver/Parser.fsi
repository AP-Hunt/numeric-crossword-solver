// Signature file for parser generated by fsyacc
module Parser
type token = 
  | EOF
  | PARSE_CHALLENGE_PREFIX_ONE_QUARTER
  | PARSE_CHALLENGE_PREFIX_SQUARES
  | LAST
  | PLUS
  | OF
  | DIGITS
  | FIRST
  | DIRECTION_ACROSS
  | DIRECTION_DOWN
  | MINUS
  | AND
  | COLON
  | COMMA
  | LOCATION of (Location)
  | INT of (int)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_PARSE_CHALLENGE_PREFIX_ONE_QUARTER
    | TOKEN_PARSE_CHALLENGE_PREFIX_SQUARES
    | TOKEN_LAST
    | TOKEN_PLUS
    | TOKEN_OF
    | TOKEN_DIGITS
    | TOKEN_FIRST
    | TOKEN_DIRECTION_ACROSS
    | TOKEN_DIRECTION_DOWN
    | TOKEN_MINUS
    | TOKEN_AND
    | TOKEN_COLON
    | TOKEN_COMMA
    | TOKEN_LOCATION
    | TOKEN_INT
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_root
    | NONTERM_challenge
    | NONTERM_question
    | NONTERM_number_list
    | NONTERM_location
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> (Challenge option) 
